name: Performance

on:
  schedule:
    # Every Sunday at 6 AM UTC (after weekly maintenance window)
    - cron: "0 6 * * 0"
  workflow_dispatch:
    inputs:
      run_large:
        description: "Include 1M-row benchmarks (slow)"
        required: false
        default: "false"

concurrency:
  group: performance
  cancel-in-progress: false

jobs:
  # ── Query benchmarks ───────────────────────────────────────────────────────
  benchmark-queries:
    name: DuckDB query benchmarks
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install dependencies
        run: pip install duckdb pytest pytest-asyncio

      - name: Run small + medium benchmarks
        run: |
          pytest tests/benchmarks/test_query_performance.py \
            -m "benchmark and not slow" \
            -v --tb=short \
            --junit-xml=benchmark-results.xml

      - name: Run large benchmarks (1M rows)
        if: ${{ github.event.inputs.run_large == 'true' }}
        run: |
          pytest tests/benchmarks/test_query_performance.py \
            -m "benchmark and slow" \
            -v --tb=short \
            --junit-xml=benchmark-large-results.xml

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: "benchmark*-results.xml"
          retention-days: 90

  # ── In-process load test ───────────────────────────────────────────────────
  load-test:
    name: Ingestion load test
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install dependencies
        run: pip install pytest pytest-asyncio

      - name: Run load test
        run: |
          pytest tests/load/ingestion_load_test.py \
            -m load \
            -v --tb=short \
            --junit-xml=load-test-results.xml

      - name: Upload load test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results
          path: load-test-results.xml
          retention-days: 90

  # ── Summary ────────────────────────────────────────────────────────────────
  performance-gate:
    name: Performance gate
    runs-on: ubuntu-latest
    needs: [benchmark-queries, load-test]
    if: always()
    steps:
      - name: Report status
        run: |
          bench="${{ needs.benchmark-queries.result }}"
          load="${{ needs.load-test.result }}"
          if [ "$bench" = "success" ] && [ "$load" = "success" ]; then
            echo "All performance checks passed."
          else
            echo "Performance regression detected — bench=$bench load=$load"
            exit 1
          fi
